{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb35cb51-d6a4-4d47-af1d-eb57215d5cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b7bf0b-dab6-4670-a69a-44fc7681853d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181b8969-65b6-4fd6-bbed-2a193fbbfb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(224, padding=24),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(0.05, 0.05, 0.05, 0.05),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_datasset = datasets.ImageFolder(root='./data/rsna_pneumonia/test/', transform=test_transform)\n",
    "val_datasset = datasets.ImageFolder(root='./data/rsna_pneumonia/val/', transform=test_transform)\n",
    "train_datasset = datasets.ImageFolder(root='./data/rsna_pneumonia/train/', transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22aa59dc-ad0d-4e6e-bee6-5af32797669a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_datasset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_datasset, batch_size=128,\n",
    "                                          shuffle=False, num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_datasset, batch_size=128,\n",
    "                                          shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f52e722-b5a1-45bc-b6be-58b9b021a1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_classifer_epoch(net, trainloader,\n",
    "                optimizer, device):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.to(device))\n",
    "        loss = loss_func(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss/(batch_idx+1)\n",
    "    train_acc = correct/total\n",
    "    return train_acc, train_loss\n",
    "\n",
    "def test_classifer_accuracy(net, testloader, device):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            targets = targets.to(device)\n",
    "            outputs = net(inputs.to(device))\n",
    "            loss = loss_func(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    test_acc = correct/total\n",
    "    test_loss = test_loss/(batch_idx+1)\n",
    "    return test_acc, test_loss\n",
    "\n",
    "def get_preds_labels(net, testloader, device):\n",
    "    net.eval()\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            outputs = net(inputs.to(device))\n",
    "            predicted = torch.softmax(outputs, dim=1).detach()\n",
    "            preds.append(predicted)\n",
    "            true_labels.append(targets)\n",
    "        preds = torch.cat(preds)\n",
    "        true_labels = torch.cat(true_labels)\n",
    "    return preds.cpu().numpy(), true_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dda54dd-2a88-4863-98c0-08136a985d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(net, epochs, trainloader, validloader,\n",
    "          seed, save_path, device):\n",
    "    best_acc = -np.inf\n",
    "    test_acc_history = []\n",
    "    optimizer = optim.AdamW(net.parameters(),\n",
    "                          lr=5e-5,)#     weight_decay=5e-4\n",
    "    for epoch in range(epochs):\n",
    "        train_acc, train_loss  = train_classifer_epoch(net, trainloader, optimizer,\n",
    "                                                      device)\n",
    "        test_acc, test_loss = test_classifer_accuracy(net, validloader, device)\n",
    "        test_acc_history.append(test_acc)\n",
    "        print(f'epoch ({epoch+1})| Train loss {round(train_loss, 2)}| Train accuracy {round(train_acc, 2)}| Test accuracy {round(test_acc, 2)}| Test loss {round(test_loss, 2)}')\n",
    "        if best_acc < test_acc:\n",
    "            print('Saving model...')\n",
    "            model_state = {'net': net.state_dict(),\n",
    "                           'opti': optimizer.state_dict(),\n",
    "                           'epoch': epoch,\n",
    "                           'seed': seed,\n",
    "                           'acc': test_acc,'epoch': epoch,\n",
    "                           'test_acc_history':test_acc_history}\n",
    "            torch.save(model_state, save_path)\n",
    "            best_acc = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10316f68-b334-4b63-adba-533bc4233976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torchvision.models.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459fe652-b054-4c10-8717-ec5036e8ee35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def modify_model_output_classes(model, num_classes):\n",
    "    if hasattr(model, 'fc'):\n",
    "        # Common case for models like ResNet\n",
    "        in_features = model.fc.in_features\n",
    "        new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "        model.fc = new_classifier\n",
    "        return model\n",
    "    \n",
    "    elif hasattr(model, 'classifier'):\n",
    "        if isinstance(model.classifier, nn.Linear):\n",
    "            # Common case for models like densenet, vgg\n",
    "            in_features = model.classifier.in_features\n",
    "            new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "            model.classifier = new_classifier\n",
    "            return model\n",
    "        \n",
    "        if isinstance(model.classifier, nn.Sequential) and isinstance(model.classifier[1], nn.Linear):\n",
    "            # Common case for models like efficientnet_b2\n",
    "            in_features = model.classifier[1].in_features\n",
    "            new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "            model.classifier[1] = new_classifier\n",
    "            return model\n",
    "    elif hasattr(model, 'heads'):\n",
    "        # ViT Special case for models with 'heads' as the final layer\n",
    "        in_features = model.heads.head.in_features\n",
    "        new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "        model.heads.head = new_classifier\n",
    "        return model\n",
    "    elif hasattr(model, 'head'):\n",
    "        # Swin\n",
    "        in_features = model.head.in_features\n",
    "        new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "        model.head = new_classifier\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model architecture. Cannot modify output classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b027a3c-3be7-4eac-a9e9-a54bd8b81064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1)| Train loss 0.71| Train accuracy 0.67| Test accuracy 0.7| Test loss 0.65\n",
      "Saving model...\n",
      "epoch (2)| Train loss 0.61| Train accuracy 0.72| Test accuracy 0.72| Test loss 0.62\n",
      "Saving model...\n",
      "epoch (3)| Train loss 0.58| Train accuracy 0.74| Test accuracy 0.72| Test loss 0.61\n",
      "Saving model...\n",
      "epoch (4)| Train loss 0.55| Train accuracy 0.75| Test accuracy 0.72| Test loss 0.59\n",
      "Saving model...\n",
      "epoch (5)| Train loss 0.52| Train accuracy 0.77| Test accuracy 0.74| Test loss 0.58\n",
      "Saving model...\n",
      "epoch (6)| Train loss 0.49| Train accuracy 0.78| Test accuracy 0.75| Test loss 0.58\n",
      "Saving model...\n",
      "epoch (7)| Train loss 0.47| Train accuracy 0.8| Test accuracy 0.76| Test loss 0.55\n",
      "Saving model...\n",
      "epoch (8)| Train loss 0.43| Train accuracy 0.82| Test accuracy 0.75| Test loss 0.61\n",
      "epoch (9)| Train loss 0.4| Train accuracy 0.83| Test accuracy 0.75| Test loss 0.59\n",
      "epoch (10)| Train loss 0.36| Train accuracy 0.85| Test accuracy 0.75| Test loss 0.64\n",
      "epoch (11)| Train loss 0.33| Train accuracy 0.86| Test accuracy 0.75| Test loss 0.65\n",
      "epoch (12)| Train loss 0.3| Train accuracy 0.88| Test accuracy 0.75| Test loss 0.67\n",
      "epoch (13)| Train loss 0.26| Train accuracy 0.9| Test accuracy 0.76| Test loss 0.66\n",
      "epoch (14)| Train loss 0.22| Train accuracy 0.92| Test accuracy 0.76| Test loss 0.74\n",
      "epoch (15)| Train loss 0.21| Train accuracy 0.92| Test accuracy 0.75| Test loss 0.84\n",
      "epoch (16)| Train loss 0.17| Train accuracy 0.93| Test accuracy 0.77| Test loss 0.78\n",
      "Saving model...\n",
      "epoch (17)| Train loss 0.16| Train accuracy 0.94| Test accuracy 0.77| Test loss 0.8\n",
      "epoch (18)| Train loss 0.13| Train accuracy 0.95| Test accuracy 0.77| Test loss 0.88\n",
      "Saving model...\n",
      "epoch (19)| Train loss 0.12| Train accuracy 0.96| Test accuracy 0.77| Test loss 0.84\n",
      "Saving model...\n",
      "epoch (20)| Train loss 0.11| Train accuracy 0.96| Test accuracy 0.77| Test loss 0.85\n",
      "Saving model...\n",
      "epoch (21)| Train loss 0.11| Train accuracy 0.96| Test accuracy 0.77| Test loss 0.89\n",
      "Saving model...\n",
      "epoch (22)| Train loss 0.09| Train accuracy 0.97| Test accuracy 0.78| Test loss 0.98\n",
      "Saving model...\n",
      "epoch (23)| Train loss 0.08| Train accuracy 0.97| Test accuracy 0.75| Test loss 1.14\n",
      "epoch (24)| Train loss 0.08| Train accuracy 0.97| Test accuracy 0.76| Test loss 0.96\n",
      "epoch (25)| Train loss 0.09| Train accuracy 0.97| Test accuracy 0.76| Test loss 0.98\n",
      "epoch (26)| Train loss 0.08| Train accuracy 0.97| Test accuracy 0.78| Test loss 1.02\n",
      "Saving model...\n",
      "epoch (27)| Train loss 0.07| Train accuracy 0.98| Test accuracy 0.78| Test loss 0.97\n",
      "epoch (28)| Train loss 0.06| Train accuracy 0.98| Test accuracy 0.76| Test loss 1.11\n",
      "epoch (29)| Train loss 0.06| Train accuracy 0.98| Test accuracy 0.78| Test loss 1.04\n",
      "epoch (30)| Train loss 0.05| Train accuracy 0.98| Test accuracy 0.77| Test loss 1.09\n",
      "epoch (31)| Train loss 0.05| Train accuracy 0.98| Test accuracy 0.78| Test loss 1.07\n",
      "Saving model...\n",
      "epoch (32)| Train loss 0.04| Train accuracy 0.98| Test accuracy 0.78| Test loss 1.06\n",
      "Saving model...\n",
      "epoch (33)| Train loss 0.05| Train accuracy 0.98| Test accuracy 0.76| Test loss 1.09\n",
      "epoch (34)| Train loss 0.04| Train accuracy 0.98| Test accuracy 0.78| Test loss 1.13\n",
      "epoch (85)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.39\n",
      "epoch (86)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.45\n",
      "epoch (87)| Train loss 0.03| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.37\n",
      "epoch (88)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.77| Test loss 1.42\n",
      "epoch (89)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.5\n",
      "epoch (90)| Train loss 0.03| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.38\n",
      "epoch (91)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.77| Test loss 1.41\n",
      "epoch (92)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.36\n",
      "epoch (93)| Train loss 0.01| Train accuracy 0.99| Test accuracy 0.79| Test loss 1.43\n",
      "epoch (94)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.76| Test loss 1.54\n",
      "epoch (95)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.43\n",
      "epoch (96)| Train loss 0.02| Train accuracy 0.99| Test accuracy 0.78| Test loss 1.44\n",
      "epoch (97)| Train loss 0.01| Train accuracy 1.0| Test accuracy 0.78| Test loss 1.43\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seeds = list(range(16, 20))\n",
    "# 'resnet18' , \n",
    "# 'vit_b_16'\n",
    "# 'swin_s', - one is missing\n",
    "# 'efficientnet_b2',\n",
    "seed_counter = 0\n",
    "for model_type in [  'densenet121']:\n",
    "    for i in range(4):\n",
    "        seed = seeds[seed_counter]\n",
    "        torch.random.manual_seed(seed)\n",
    "        model = torch.hub.load(\"pytorch/vision\", model_type,\n",
    "                               weights=\"IMAGENET1K_V1\").to(device)\n",
    "        model = modify_model_output_classes(model, 3)\n",
    "        train(model, 100, train_loader, test_loader, seed,\n",
    "              f'./models/xray/{model_type}_{i}.ckpt', device)\n",
    "        seed_counter+=1\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab04b9e-5d57-4d83-8276-40928487649e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for model_type in ['resnet18' ,  'vit_b_16','swin_s', 'efficientnet_b2', 'densenet121']: \n",
    "#     model = torch.hub.load(\"pytorch/vision\", model_type,\n",
    "#                                weights=\"IMAGENET1K_V1\").to(device)\n",
    "#     model = modify_model_output_classes(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93843c5f-b36f-4d55-bf65-f24e22e933c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./models/x_ray_victim.ckpt')['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9c320-4a01-4e34-95aa-e3fa916f9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = get_preds_labels(net, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10b3d9-1e2b-4e23-8df6-fc388eb119ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "def roc_curve_ood(preds, labels):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, preds)\n",
    "    thres_idx = np.argmin(np.square(tpr-0.95))\n",
    "    thres95 = thresholds[thres_idx]\n",
    "    auc_score = roc_auc_score(labels, preds)\n",
    "    return thres95, auc_score\n",
    "\n",
    "\n",
    "thres95, auc = roc_curve_ood(preds, labels)\n",
    "print(f'AUROC: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5e1b6-ad1c-4776-97cb-bb5149ec8c11",
   "metadata": {},
   "source": [
    "### Adversarial attack(un-adaptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082388f-9e2d-43d1-9b6b-bfd434992c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientPGDAttack(model, inputs, labels,\n",
    "                                   loss_func, eps, device):\n",
    "    pertubation = torch.zeros(inputs.size()).to(device)\n",
    "    samples = inputs.to(device)\n",
    "    for i in range(50):\n",
    "        pertubation = torch.autograd.Variable(pertubation, requires_grad=True)\n",
    "        classifer_outputs = model((samples+pertubation))\n",
    "        classifier_labels = labels.to(device)\n",
    "        loss = loss_func(classifer_outputs, classifier_labels)\n",
    "        loss.backward()\n",
    "        gradient = torch.ge(pertubation.grad.data, 0)\n",
    "        pertubation = torch.add(pertubation.data, +(eps/10)*gradient).detach()    \n",
    "        pertubation = torch.clamp(pertubation, min = -eps, max= eps)\n",
    "        del classifer_outputs, classifier_labels, gradient, loss\n",
    "    return (samples+pertubation)\n",
    "\n",
    "def gen_adv_dataset(model, loader, eps):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for samples, targets in loader:\n",
    "        labels.append(targets)\n",
    "        samples, targets = samples.to(device), targets.to(device)\n",
    "\n",
    "        pertubed = GradientPGDAttack(model, samples, targets,\n",
    "                                  BinaryCrossEntropy(),\n",
    "                                  eps, device).detach().cpu()\n",
    "        data.append(pertubed)\n",
    "    data = torch.cat(data)\n",
    "    labels = torch.cat(labels)\n",
    "    dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=128,\n",
    "                      shuffle=False,num_workers =6,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002030cb-a4ca-45aa-a44b-abb2b539d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_dataloader = gen_adv_dataset(net, test_loader, 8/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf7d43-53a4-4608-8dda-236baaba679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = get_preds_labels(net, adv_dataloader, device)\n",
    "thres95, auc = roc_curve_ood(preds, labels)\n",
    "print(f'AUROC: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018c3a6-35e8-443a-93ba-f64db8ae22ec",
   "metadata": {},
   "source": [
    "# MGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76338118-08aa-4e07-98d8-2a50b5f6ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc80a8-045f-45e1-8ba7-6f09e437e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_pen_rep(net, x):\n",
    "    out = net.conv1(x)\n",
    "    out = net.bn1(out)\n",
    "    out = net.relu(out)\n",
    "    out = net.layer1(out)\n",
    "    out = net.layer2(out)\n",
    "    out = net.layer3(out)\n",
    "    out = net.layer4(out)\n",
    "    out = net.avgpool(out)\n",
    "    return out\n",
    "\n",
    "def get_pen_reps(net, loader, device):\n",
    "    net.eval()\n",
    "    reps = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs, targets) in loader:\n",
    "            inputs= inputs.to(device)\n",
    "            input_reps = net_pen_rep(net, inputs)\n",
    "            input_reps = input_reps.detach().cpu()\n",
    "            reps.append(input_reps)\n",
    "        reps = torch.cat(reps).squeeze()\n",
    "        return reps    \n",
    "    \n",
    "def calc_MGM_params(net, trainloader):\n",
    "    train_reps = get_pen_reps(net,\n",
    "                              trainloader,\n",
    "                              device).t()\n",
    "    m = train_reps.size(1) \n",
    "    f_dim = train_reps.size(0)\n",
    "    mu = train_reps.mean(dim = 1,  keepdim=True)\n",
    "    train_reps -= mu\n",
    "    cov = (1/ (m+1)) * train_reps.matmul(train_reps.t()) +1e-10*torch.eye(f_dim, f_dim)\n",
    "    R = torch.cholesky(cov, upper=False)\n",
    "    R_diag_sum = R.diag().sum()\n",
    "    R_inv = torch.cholesky_inverse(R)\n",
    "    return f_dim, R_diag_sum, R_inv, mu\n",
    "    \n",
    "def calc_likelihood(rep, f_dim, R_diag_sum, R_inv, mu):\n",
    "    Z = -0.5*R_diag_sum -f_dim*np.log(2*np.pi)\n",
    "    log_exp = (R_inv.matmul(rep - mu)**2).sum(dim=0)\n",
    "    return Z+log_exp\n",
    "    \n",
    "def predict_liklihood(net, loader,f_dim, R_diag_sum, R_inv, mu):\n",
    "    net.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs, targets) in loader:\n",
    "            inputs= inputs.to(device)\n",
    "            reps = net_pen_rep(net, inputs)\n",
    "            reps = reps.detach().cpu()\n",
    "            pred = calc_likelihood(reps.squeeze().t(), f_dim, \n",
    "                                   R_diag_sum, R_inv, mu)\n",
    "            preds.append(pred)\n",
    "        preds = torch.cat(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7b30b-ade2-4bcb-9b75-bbafcc71a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dim, R_diag_sum, R_inv, mu = calc_MGM_params(net, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9475d-5aae-4d76-9a92-b1200c78c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_likelihood = predict_liklihood(net, adv_dataloader, f_dim, R_diag_sum, R_inv, mu)\n",
    "bengin_likelihood = predict_liklihood(net, test_loader, f_dim, R_diag_sum, R_inv, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1580a4-6432-4d01-a7c7-d493659aab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adv_likelihood.numpy(), bins=100, color='r')\n",
    "plt.hist(bengin_likelihood.numpy(), bins=100, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d49bb8-cf5f-46f5-8633-df8726e58cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f284091-1183-487e-860f-545eb488db4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
