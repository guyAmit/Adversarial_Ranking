{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c11028-5110-4a8f-ba9b-3af4a9576c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fac8e1-204e-4753-8f14-28324fc3c940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abc015f-dab1-4964-b228-c00a2f12a587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dev_datasset = datasets.ImageFolder(root='./data/Sign_Classification/traffic_Data/DATA/',\n",
    "                                    transform=test_transform)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dev_datasset, [0.7, 0.15, 0.15], generator)\n",
    "val_dataset.transform = test_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100,\n",
    "                                          shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f01d491-940d-498b-afdd-d7cbb26adf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_output_classes(model, num_classes):\n",
    "    if hasattr(model, 'fc'):\n",
    "        # Common case for models like ResNet\n",
    "        in_features = model.fc.in_features\n",
    "        new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "        model.fc = new_classifier\n",
    "        return model\n",
    "    \n",
    "    elif hasattr(model, 'classifier'):\n",
    "        if isinstance(model.classifier, nn.Linear):\n",
    "            # Common case for models like densenet, vgg\n",
    "            in_features = model.classifier.in_features\n",
    "            new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "            model.classifier = new_classifier\n",
    "            return model\n",
    "        \n",
    "        if isinstance(model.classifier, nn.Sequential) and isinstance(model.classifier[1], nn.Linear):\n",
    "            # Common case for models like efficientnet_b2\n",
    "            in_features = model.classifier[1].in_features\n",
    "            new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "            model.classifier[1] = new_classifier\n",
    "            return model\n",
    "    elif hasattr(model, 'heads'):\n",
    "        # ViT Special case for models with 'heads' as the final layer\n",
    "        in_features = model.heads.head.in_features\n",
    "        new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "        model.heads.head = new_classifier\n",
    "        return model\n",
    "    elif hasattr(model, 'head'):\n",
    "        # Swin\n",
    "        in_features = model.head.in_features\n",
    "        new_classifier = nn.Linear(in_features, num_classes).to(device)\n",
    "        model.head = new_classifier\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model architecture. Cannot modify output classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de2025f-bdbd-47ab-afc2-e6900954b546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths = { 'ViT': './models/road_sign/vit_b_16_0.ckpt',\n",
    "               'ViT_copy': './models/road_sign/vit_b_16_1.ckpt',\n",
    "            'DenseNet121':'./models/road_sign/densenet121_0.ckpt',\n",
    "            'DenseNet121_copy':'./models/road_sign/densenet121_1.ckpt',\n",
    "            'Efficientnet_b2': './models/road_sign/efficientnet_b2_0.ckpt',\n",
    "            'Efficientnet_b2_copy': './models/road_sign/efficientnet_b2_1.ckpt',\n",
    "            'Resnet18': './models/road_sign/resnet18_0.ckpt',\n",
    "            'Resnet18_copy': './models/road_sign/resnet18_1.ckpt',\n",
    "            'Swin_s': './models/road_sign/swin_s_0.ckpt',\n",
    "            'Swin_s_copy': './models/road_sign/swin_s_1.ckpt'}\n",
    "                    \n",
    "\n",
    "models = {'ViT': 'vit_b_16', 'ViT_copy': 'vit_b_16', \n",
    "          'DenseNet121': 'densenet121', 'DenseNet121_copy': 'densenet121',\n",
    "          'Efficientnet_b2':'efficientnet_b2', 'Efficientnet_b2_copy':'efficientnet_b2',\n",
    "          'Resnet18': 'resnet18', 'Resnet18_copy': 'resnet18',\n",
    "          'Swin_s': 'swin_s', 'Swin_s_copy': 'swin_s'}\n",
    "\n",
    "model_names = ['ViT', 'DenseNet121', 'Efficientnet_b2', 'Resnet18', 'Swin_s',\n",
    "              'ViT_copy', 'DenseNet121_copy', 'Efficientnet_b2_copy',\n",
    "               'Resnet18_copy', 'Swin_s_copy']\n",
    "\n",
    "\n",
    "eps = 1/255\n",
    "alpha = 0.25/255\n",
    "iters = 10\n",
    "attack = 'PGD'\n",
    "save_path = 'save_path_with_a_lot_of_memory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92801cc3-449f-4da9-86ae-db6f30aa1a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "# for model_name in model_names:\n",
    "#     m = torch.hub.load(\"pytorch/vision\", models[model_name],\n",
    "#                            weights=\"IMAGENET1K_V1\").to(device)\n",
    "#     m = modify_model_output_classes(m, 58)\n",
    "#     m.load_state_dict(torch.load(model_paths[model_name])['net'])\n",
    "#     print(f'loaded {model_paths[model_name]}')\n",
    "#     # atk = torchattacks.PGD(m,random_start=False, eps=eps,alpha=alpha,steps=iters)\n",
    "#     atk = torchattacks.MIFGSM(m, eps=eps, steps=iters, decay=0.9)\n",
    "#     # atk = torchattacks.FGSM(m, eps=eps)\n",
    "#     true_labels = []\n",
    "#     adv_inputs = []\n",
    "#     sample_indexes = []\n",
    "#     sample_num = 0\n",
    "\n",
    "#     for batch, labels in test_loader:\n",
    "#         batch, labels = batch.to(device), labels.to(device)\n",
    "#         sample_index = torch.arange(sample_num, sample_num+labels.size(0))\n",
    "#         adv_samples = atk(batch, labels)\n",
    "#         pred_labels = m(adv_samples).argmax(dim=1)\n",
    "#         mask = pred_labels.eq(labels)\n",
    "#         if mask.all():\n",
    "#             continue\n",
    "#         else:\n",
    "#             adv_samples = adv_samples[~mask]\n",
    "#             labels = labels[~mask]\n",
    "#             sample_index = sample_index[~mask.cpu()]\n",
    "#             true_labels.append(labels.to('cpu'))\n",
    "#             adv_inputs.append(adv_samples.to('cpu'))\n",
    "#             sample_indexes.append(sample_index)\n",
    "#         sample_num += labels.size(0)\n",
    "        \n",
    "#     true_labels = torch.cat(true_labels)\n",
    "#     adv_inputs = torch.cat(adv_inputs, dim=0)\n",
    "#     sample_indexes = torch.cat(sample_indexes)\n",
    "\n",
    "#     torch.save(sample_indexes, f'./adv_samples/{attack}/road_sign/{model_name}_index.ckpt')\n",
    "#     torch.save(true_labels, f'./adv_samples/{attack}/road_sign/{model_name}_labels.ckpt')\n",
    "#     torch.save(adv_inputs, f'./adv_samples/{attack}/road_sign/{model_name}_samples.ckpt')\n",
    "#     del atk, m\n",
    "     \n",
    "batch, labels = next(iter(test_loader))\n",
    "batch, labels = batch.to(device), labels.to(device)\n",
    "\n",
    "for model_name in model_names:\n",
    "    m = torch.hub.load(\"pytorch/vision\", models[model_name],\n",
    "                           weights=\"IMAGENET1K_V1\").to(device)\n",
    "    m = modify_model_output_classes(m, 58)\n",
    "    m.load_state_dict(torch.load(model_paths[model_name])['net'])\n",
    "    m.eval()\n",
    "    atk = torchattacks.PGD(m, random_start=True, \n",
    "                           eps=eps,alpha=alpha,steps=iters)\n",
    "\n",
    "    for run in range(0, 20):\n",
    "        true_labels = labels.to('cpu')\n",
    "        adv_samples = atk(batch, labels).to('cpu')\n",
    "    \n",
    "        torch.save(true_labels, os.path.join(save_path,\n",
    "                                             f'adv_samples/{attack}/road_sign/pertubation_ranking/{model_name}_labels_run_{run}.ckpt'))\n",
    "        torch.save(adv_samples,  os.path.join(save_path,\n",
    "                                             f'adv_samples/{attack}/road_sign/pertubation_ranking/{model_name}_samples_run_{run}.ckpt'))\n",
    "    del atk, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a9100d-440d-426f-813a-1b567c3c9d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# m = torch.hub.load(\"pytorch/vision\", models['Swin_s'],\n",
    "#                        weights=\"IMAGENET1K_V1\")\n",
    "# m = modify_model_output_classes(m, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b5119b-b319-4397-9455-61035abac812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# m.load_state_dict(torch.load(model_paths['Swin_s'])['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2ef19a-2ebc-403a-9380-fcde3ff239c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weight = m.fc.weight[:3, :]\n",
    "# bias = m.fc.bias[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ac1cb7-d721-4397-b1a3-35fa7ed8ca1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# m.fc = nn.Linear(512, 3)\n",
    "# m.fc.weight.data = weight\n",
    "# m.fc.bias.data = bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e81464ab-09d7-48fb-8a2c-33eb05538a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# state = {'net': m.state_dict()}\n",
    "# torch.save(state, './models/xray/resnet18_0.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7661631c-cf4f-412c-94e3-6079644c78a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "other_list = {'Resnet18': ['ViT', 'Resnet18_copy', 'DenseNet121', 'Efficientnet_b2', 'Swin_s'],\n",
    "              'Swin_s': ['ViT', 'Swin_s_copy', 'DenseNet121', 'Efficientnet_b2', 'Resnet18'],\n",
    "              'ViT': ['DenseNet121', 'ViT_copy', 'Efficientnet_b2', 'Resnet18', 'Swin_s'],\n",
    "              'DenseNet121': ['ViT', 'DenseNet121_copy', 'Efficientnet_b2', 'Resnet18', 'Swin_s'],\n",
    "              'Efficientnet_b2': ['ViT', 'Efficientnet_b2_copy', 'DenseNet121', 'Resnet18', 'Swin_s'],            \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f6ff2-9c59-41d5-b0f8-5220127640b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for surogate, others in other_list.items():\n",
    "    \n",
    "#     true_labels= torch.load(f'./adv_samples/{attack}/road_sign/{surogate}_labels.ckpt')\n",
    "#     adv_inputs = torch.load(f'./adv_samples/{attack}/road_sign/{surogate}_samples.ckpt')\n",
    "#     sample_index = torch.load(f'./adv_samples/{attack}/road_sign/{surogate}_index.ckpt')\n",
    "    \n",
    "#     adv_dataset = torch.utils.data.TensorDataset(adv_inputs, true_labels, sample_index)\n",
    "#     adv_loader = torch.utils.data.DataLoader(adv_dataset, batch_size=64,\n",
    "#                                              shuffle=False, num_workers=4)\n",
    "#     print(f'Testing model {surogate}')\n",
    "#     results_df = {}\n",
    "#     for test_model_name in others:\n",
    "        \n",
    "#         results_df[f'{test_model_name}_pred_label'] = []\n",
    "#         results_df[f'{test_model_name}_pred_conf'] = []\n",
    "#         results_df[f'{test_model_name}_true_conf'] = []\n",
    "#         results_df[f'{test_model_name}_true_label'] = []\n",
    "        \n",
    "#         path = model_paths[test_model_name]\n",
    "#         model = models[test_model_name]\n",
    "        \n",
    "#         m = torch.hub.load(\"pytorch/vision\", model,\n",
    "#                                weights=\"IMAGENET1K_V1\").to(device)\n",
    "#         m = modify_model_output_classes(m, 58)\n",
    "#         m.load_state_dict(torch.load(path)['net'])\n",
    "#         print(f'loaded {path}')\n",
    "#         m.eval()\n",
    "\n",
    "#         true_labels = []\n",
    "#         adv_inputs = []\n",
    "#         with torch.no_grad():\n",
    "#             for batch, labels, _ in adv_loader:\n",
    "#                 batch = batch.to(device)\n",
    "#                 outputs = torch.softmax(m(batch), dim=1).cpu()\n",
    "#                 max_return = outputs.max(dim=1)\n",
    "                \n",
    "#                 results_df[f'{test_model_name}_pred_label'].extend(max_return.indices.numpy().tolist())\n",
    "#                 results_df[f'{test_model_name}_pred_conf'].extend(max_return.values.numpy().tolist())\n",
    "                \n",
    "#                 true_conf = torch.gather(outputs, dim=1, index=labels.view(-1, 1)).view(-1)\n",
    "#                 results_df[f'{test_model_name}_true_conf'].extend(true_conf.cpu().numpy().tolist())\n",
    "#                 results_df[f'{test_model_name}_true_label'].extend(labels.numpy().tolist())\n",
    "\n",
    "#         del m\n",
    "        \n",
    "#     results_df['sample_index'] = []\n",
    "#     for _, _, index in adv_loader:\n",
    "#         results_df['sample_index'].extend(index.numpy().tolist())\n",
    "        \n",
    "#     results_df = pd.DataFrame(results_df)\n",
    "#     results_df.to_csv(f'./results/{attack}/road_sign_surogate_{surogate}.csv', index=False)\n",
    "\n",
    "# for surogate, others in other_list.items():\n",
    "    \n",
    "#     true_labels= torch.load(f'./adv_samples/{attack}/xray/{surogate}_labels.ckpt')\n",
    "#     adv_inputs = torch.load(f'./adv_samples/{attack}/xray/{surogate}_samples.ckpt')\n",
    "#     sample_index = torch.load(f'./adv_samples/{attack}/xray/{surogate}_index.ckpt')\n",
    "    \n",
    "#     adv_dataset = torch.utils.data.TensorDataset(adv_inputs, true_labels, sample_index)\n",
    "#     adv_loader = torch.utils.data.DataLoader(adv_dataset, batch_size=64,\n",
    "#                                              shuffle=False, num_workers=4)\n",
    "#     print(f'Testing model {surogate}')\n",
    "#     results_df = {}\n",
    "#     for test_model_name in others:\n",
    "        \n",
    "#         results_df[f'{test_model_name}_pred_label'] = []\n",
    "#         results_df[f'{test_model_name}_pred_conf'] = []\n",
    "#         results_df[f'{test_model_name}_true_conf'] = []\n",
    "#         results_df[f'{test_model_name}_true_label'] = []\n",
    "        \n",
    "#         path = model_paths[test_model_name]\n",
    "#         model = models[test_model_name]\n",
    "        \n",
    "#         m = torch.hub.load(\"pytorch/vision\", model,\n",
    "#                                weights=\"IMAGENET1K_V1\").to(device)\n",
    "#         m = modify_model_output_classes(m, 3)\n",
    "#         m.load_state_dict(torch.load(path)['net'])\n",
    "#         print(f'loaded {path}')\n",
    "#         m.eval()\n",
    "\n",
    "#         true_labels = []\n",
    "#         adv_inputs = []\n",
    "#         with torch.no_grad():\n",
    "#             for batch, labels, _ in adv_loader:\n",
    "#                 batch = batch.to(device)\n",
    "#                 outputs = torch.softmax(m(batch), dim=1).cpu()\n",
    "#                 max_return = outputs.max(dim=1)\n",
    "                \n",
    "#                 results_df[f'{test_model_name}_pred_label'].extend(max_return.indices.numpy().tolist())\n",
    "#                 results_df[f'{test_model_name}_pred_conf'].extend(max_return.values.numpy().tolist())\n",
    "                \n",
    "#                 true_conf = torch.gather(outputs, dim=1, index=labels.view(-1, 1)).view(-1)\n",
    "#                 results_df[f'{test_model_name}_true_conf'].extend(true_conf.cpu().numpy().tolist())\n",
    "#                 results_df[f'{test_model_name}_true_label'].extend(labels.numpy().tolist())\n",
    "\n",
    "#         del m\n",
    "#     results_df['sample_index'] = []\n",
    "#     for _, _, index in adv_loader:\n",
    "#         results_df['sample_index'].extend(index.numpy().tolist())\n",
    "#     results_df = pd.DataFrame(results_df)\n",
    "#     results_df.to_csv(f'./results/{attack}/xray_surogate_{surogate}.csv', index=False)\n",
    "\n",
    "for surogate, others in other_list.items():\n",
    "    print(f'Testing model {surogate}')\n",
    "    for run in range(20):\n",
    "        true_labels= torch.load(os.path.join(save_path,\n",
    "                                             f'adv_samples/{attack}/road_sign/pertubation_ranking/{surogate}_labels_run_{run}.ckpt'))\n",
    "        adv_inputs = torch.load(os.path.join(save_path,\n",
    "                                             f'adv_samples/{attack}/road_sign/pertubation_ranking/{surogate}_samples_run_{run}.ckpt'))\n",
    "        run_df = {}\n",
    "        for test_model_name in others:\n",
    "\n",
    "            m = torch.hub.load(\"pytorch/vision\", models[test_model_name],\n",
    "                                   weights=\"IMAGENET1K_V1\").to(device)\n",
    "            m = modify_model_output_classes(m, 58)\n",
    "            m.load_state_dict(torch.load(model_paths[test_model_name])['net'])\n",
    "            m.eval()\n",
    "\n",
    "            batch = adv_inputs.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = torch.softmax(m(batch), dim=1).cpu()\n",
    "            max_return = outputs.max(dim=1)\n",
    "            \n",
    "            run_df[f'{test_model_name}_pred_label'] = (max_return.indices.numpy().tolist())\n",
    "            run_df[f'{test_model_name}_pred_conf'] = max_return.values.numpy()\n",
    "\n",
    "            true_conf = torch.gather(outputs, dim=1, index=true_labels.view(-1, 1)).view(-1)\n",
    "            run_df[f'{test_model_name}_true_conf'] = (true_conf.cpu().numpy().tolist())\n",
    "            run_df[f'{test_model_name}_true_label'] = (true_labels.numpy().tolist())\n",
    "\n",
    "            del m\n",
    "        run_df = pd.DataFrame(run_df)\n",
    "        run_df.to_csv(f'./results/pertubation_ranking/road_sign/run_{run}_xray_surogate_{surogate}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80dcd7c-09a3-4651-802a-5ee5f202f721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.gather(outputs, dim=1, index=labels.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16155560-efac-4949-a038-5ba39e014445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/vit_b_16_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/densenet121_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/efficientnet_b2_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/resnet18_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/swin_s_0.ckpt\n"
     ]
    }
   ],
   "source": [
    "df = {}\n",
    "batch, labels = next(iter(test_loader))\n",
    "batch, labels = batch.to(device), labels.to(device)\n",
    "for model_name in model_names:\n",
    "    if '_copy' in model_name:\n",
    "        continue\n",
    "    m = torch.hub.load(\"pytorch/vision\", models[model_name],\n",
    "                           weights=\"IMAGENET1K_V1\").to(device)\n",
    "    m = modify_model_output_classes(m, 58)\n",
    "    m.load_state_dict(torch.load(model_paths[model_name])['net'])\n",
    "    print(f'loaded {model_paths[model_name]}')\n",
    "    m.eval()\n",
    "    df[f'{model_name}_probs'] = []\n",
    "    df[f'{model_name}_noise_probs'] = []\n",
    "    with torch.no_grad():\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        probs = torch.softmax(m(batch), dim=1).max(dim=1).values\n",
    "        noise_probs =torch.softmax(m(batch+\n",
    "                                     (16/255)*torch.randn_like(batch)),\n",
    "                                   dim=1).max(dim=1).values\n",
    "\n",
    "        df[f'{model_name}_probs'].extend(probs.detach().cpu().numpy().tolist())\n",
    "        df[f'{model_name}_noise_probs'].extend(noise_probs.detach().cpu().numpy().tolist())\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(f'./results/pertubation_ranking/road_sign_all_preds.csv', index=False)\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33e0b1bf-6212-4d79-a805-a9f8f818dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, org_size, inter_size):\n",
    "        self.org_size = org_size\n",
    "        self.inter_size = inter_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = transforms.functional.resize(img, self.inter_size)\n",
    "        return transforms.functional.resize(img, self.org_size)\n",
    "    \n",
    "class Compress(object):\n",
    "    def __init__(self,):\n",
    "        self.encode_param =  [int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = (img.cpu().numpy()*255).astype(np.uint8).transpose([1,2,0])\n",
    "        result, encimg = cv2.imencode('.jpg', img, self.encode_param)\n",
    "        decimg = cv2.imdecode(encimg, 1)\n",
    "        return torch.Tensor(decimg.transpose(2,0,1))/255\n",
    "    \n",
    "class Adv_dataset_with_transforms(Dataset):\n",
    "    def __init__(self, adv_inputs, true_labels, sample_index, transforms):\n",
    "        self.data = adv_inputs\n",
    "        self.target = true_labels\n",
    "        self.sample_index = sample_index\n",
    "        self.transform = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        x = self.transform(x)\n",
    "        \n",
    "        y = self.target[index]\n",
    "        sample_index = self.sample_index[index]\n",
    "        return x, y, sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5df8b39a-5c32-40c2-940b-480344e6524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = 'combined'\n",
    "\n",
    "if transform == 'compression':\n",
    "    trans = Compress()\n",
    "elif transform == 'resize':\n",
    "    trans = Resize(224, 200)\n",
    "elif transform == 'combined':\n",
    "    trans = transforms.Compose([\n",
    "        Compress(),\n",
    "        Resize(224, 200)\n",
    "    ])\n",
    "else:\n",
    "    trans = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6866839a-fd43-40f0-b9ee-7b7a551bdeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/vit_b_16_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/resnet18_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/densenet121_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/efficientnet_b2_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/swin_s_0.ckpt\n",
      "Testing model Swin_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/vit_b_16_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/swin_s_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/densenet121_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/efficientnet_b2_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/resnet18_0.ckpt\n",
      "Testing model ViT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/densenet121_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/vit_b_16_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/efficientnet_b2_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/resnet18_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/swin_s_0.ckpt\n",
      "Testing model DenseNet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/vit_b_16_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/densenet121_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/efficientnet_b2_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/resnet18_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/swin_s_0.ckpt\n",
      "Testing model Efficientnet_b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/vit_b_16_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/efficientnet_b2_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/densenet121_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/resnet18_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/guy5/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./models/road_sign/swin_s_0.ckpt\n"
     ]
    }
   ],
   "source": [
    "for surogate, others in other_list.items():\n",
    "    \n",
    "    true_labels= torch.load(f'./adv_samples/PGD/road_sign/{surogate}_labels.ckpt')\n",
    "    adv_inputs = torch.load(f'./adv_samples/PGD/road_sign/{surogate}_samples.ckpt')\n",
    "    sample_index = torch.load(f'./adv_samples/PGD/road_sign/{surogate}_index.ckpt')\n",
    "    \n",
    "    adv_dataset = torch.utils.data.TensorDataset(adv_inputs, true_labels, sample_index)\n",
    "    adv_loader = torch.utils.data.DataLoader(adv_dataset, batch_size=64,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "    print(f'Testing model {surogate}')\n",
    "    results_df = {}\n",
    "    for test_model_name in others:\n",
    "        \n",
    "        results_df[f'{test_model_name}_pred_label'] = []\n",
    "        results_df[f'{test_model_name}_pred_conf'] = []\n",
    "        results_df[f'{test_model_name}_true_conf'] = []\n",
    "        results_df[f'{test_model_name}_true_label'] = []\n",
    "        \n",
    "        path = model_paths[test_model_name]\n",
    "        model = models[test_model_name]\n",
    "        \n",
    "        m = torch.hub.load(\"pytorch/vision\", model,\n",
    "                               weights=\"IMAGENET1K_V1\").to(device)\n",
    "        m = modify_model_output_classes(m, 58)\n",
    "        m.load_state_dict(torch.load(path)['net'])\n",
    "        print(f'loaded {path}')\n",
    "        m.eval()\n",
    "\n",
    "        true_labels = []\n",
    "        adv_inputs = []\n",
    "        with torch.no_grad():\n",
    "            for batch, labels, _ in adv_loader:\n",
    "                batch = batch.to(device)\n",
    "                outputs = torch.softmax(m(batch), dim=1).cpu()\n",
    "                max_return = outputs.max(dim=1)\n",
    "                \n",
    "                results_df[f'{test_model_name}_pred_label'].extend(max_return.indices.numpy().tolist())\n",
    "                results_df[f'{test_model_name}_pred_conf'].extend(max_return.values.numpy().tolist())\n",
    "                \n",
    "                true_conf = torch.gather(outputs, dim=1, index=labels.view(-1, 1)).view(-1)\n",
    "                results_df[f'{test_model_name}_true_conf'].extend(true_conf.cpu().numpy().tolist())\n",
    "                results_df[f'{test_model_name}_true_label'].extend(labels.numpy().tolist())\n",
    "\n",
    "        del m\n",
    "        \n",
    "    results_df['sample_index'] = []\n",
    "    for _, _, index in adv_loader:\n",
    "        results_df['sample_index'].extend(index.numpy().tolist())\n",
    "        \n",
    "    results_df = pd.DataFrame(results_df)\n",
    "    results_df.to_csv(f'./results/transforms/{transform}/road_sign_surogate_{surogate}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb7503-6911-421c-8845-b9f70451066c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c2ae0-1c7d-40c4-a692-4a6ddc59b51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
